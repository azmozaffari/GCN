{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/azadeh/.local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch)\n",
      "  Using cached triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 triton-3.0.0\n",
      "Collecting torch_geometric\n",
      "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: aiohttp in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch_geometric) (3.9.3)\n",
      "Requirement already satisfied: fsspec in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch_geometric) (2023.10.0)\n",
      "Requirement already satisfied: jinja2 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch_geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/azadeh/.local/lib/python3.11/site-packages (from torch_geometric) (6.0.0)\n",
      "Requirement already satisfied: pyparsing in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: requests in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/azadeh/anaconda3/lib/python3.11/site-packages (from torch_geometric) (4.65.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.9.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from requests->torch_geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from requests->torch_geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/azadeh/anaconda3/lib/python3.11/site-packages (from requests->torch_geometric) (2024.7.4)\n",
      "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n",
      "Requirement already satisfied: numpy in /home/azadeh/anaconda3/lib/python3.11/site-packages (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torch_geometric\n",
    "# !pip install scipy\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, in_feature_len, hidden_feature_len, output_feature_len):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.layer1 = GCNConv(in_feature_len, hidden_feature_len)\n",
    "        self.layer2 = GCNConv(hidden_feature_len, output_feature_len)\n",
    "        self.relu = F.relu\n",
    "        self.dropout = F.dropout\n",
    "\n",
    "    def forward(self, x, adj_matrix):\n",
    "        # First GCN layer\n",
    "        x = self.layer1(x, adj_matrix)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x, p=0.5)\n",
    "        # Second GCN layer\n",
    "        x = self.layer2(x, adj_matrix)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708]) 1433 7\n"
     ]
    }
   ],
   "source": [
    "input_features = dataset.num_node_features\n",
    "num_classes = dataset.num_classes\n",
    "print(dataset[0], input_features, num_classes)\n",
    "model = GCNModel(input_features, 16, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.0135\n",
      "Epoch: 002, Loss: 0.0271\n",
      "Epoch: 003, Loss: 0.0249\n",
      "Epoch: 004, Loss: 0.0230\n",
      "Epoch: 005, Loss: 0.0356\n",
      "Epoch: 006, Loss: 0.0241\n",
      "Epoch: 007, Loss: 0.0278\n",
      "Epoch: 008, Loss: 0.0306\n",
      "Epoch: 009, Loss: 0.0169\n",
      "Epoch: 010, Loss: 0.0126\n",
      "Epoch: 011, Loss: 0.0246\n",
      "Epoch: 012, Loss: 0.0178\n",
      "Epoch: 013, Loss: 0.0304\n",
      "Epoch: 014, Loss: 0.0180\n",
      "Epoch: 015, Loss: 0.0300\n",
      "Epoch: 016, Loss: 0.0190\n",
      "Epoch: 017, Loss: 0.0294\n",
      "Epoch: 018, Loss: 0.0198\n",
      "Epoch: 019, Loss: 0.0153\n",
      "Epoch: 020, Loss: 0.0116\n",
      "Epoch: 021, Loss: 0.0228\n",
      "Epoch: 022, Loss: 0.0076\n",
      "Epoch: 023, Loss: 0.0139\n",
      "Epoch: 024, Loss: 0.0220\n",
      "Epoch: 025, Loss: 0.0331\n",
      "Epoch: 026, Loss: 0.0219\n",
      "Epoch: 027, Loss: 0.0272\n",
      "Epoch: 028, Loss: 0.0193\n",
      "Epoch: 029, Loss: 0.0105\n",
      "Epoch: 030, Loss: 0.0186\n",
      "Epoch: 031, Loss: 0.0223\n",
      "Epoch: 032, Loss: 0.0208\n",
      "Epoch: 033, Loss: 0.0122\n",
      "Epoch: 034, Loss: 0.0189\n",
      "Epoch: 035, Loss: 0.0279\n",
      "Epoch: 036, Loss: 0.0143\n",
      "Epoch: 037, Loss: 0.0250\n",
      "Epoch: 038, Loss: 0.0105\n",
      "Epoch: 039, Loss: 0.0282\n",
      "Epoch: 040, Loss: 0.0161\n",
      "Epoch: 041, Loss: 0.0216\n",
      "Epoch: 042, Loss: 0.0186\n",
      "Epoch: 043, Loss: 0.0191\n",
      "Epoch: 044, Loss: 0.0199\n",
      "Epoch: 045, Loss: 0.0120\n",
      "Epoch: 046, Loss: 0.0153\n",
      "Epoch: 047, Loss: 0.0234\n",
      "Epoch: 048, Loss: 0.0120\n",
      "Epoch: 049, Loss: 0.0191\n",
      "Epoch: 050, Loss: 0.0232\n",
      "Epoch: 051, Loss: 0.0230\n",
      "Epoch: 052, Loss: 0.0125\n",
      "Epoch: 053, Loss: 0.0168\n",
      "Epoch: 054, Loss: 0.0226\n",
      "Epoch: 055, Loss: 0.0150\n",
      "Epoch: 056, Loss: 0.0151\n",
      "Epoch: 057, Loss: 0.0197\n",
      "Epoch: 058, Loss: 0.0161\n",
      "Epoch: 059, Loss: 0.0100\n",
      "Epoch: 060, Loss: 0.0259\n",
      "Epoch: 061, Loss: 0.0172\n",
      "Epoch: 062, Loss: 0.0135\n",
      "Epoch: 063, Loss: 0.0176\n",
      "Epoch: 064, Loss: 0.0243\n",
      "Epoch: 065, Loss: 0.0236\n",
      "Epoch: 066, Loss: 0.0281\n",
      "Epoch: 067, Loss: 0.0205\n",
      "Epoch: 068, Loss: 0.0164\n",
      "Epoch: 069, Loss: 0.0126\n",
      "Epoch: 070, Loss: 0.0136\n",
      "Epoch: 071, Loss: 0.0150\n",
      "Epoch: 072, Loss: 0.0248\n",
      "Epoch: 073, Loss: 0.0252\n",
      "Epoch: 074, Loss: 0.0218\n",
      "Epoch: 075, Loss: 0.0109\n",
      "Epoch: 076, Loss: 0.0167\n",
      "Epoch: 077, Loss: 0.0289\n",
      "Epoch: 078, Loss: 0.0126\n",
      "Epoch: 079, Loss: 0.0170\n",
      "Epoch: 080, Loss: 0.0135\n",
      "Epoch: 081, Loss: 0.0153\n",
      "Epoch: 082, Loss: 0.0108\n",
      "Epoch: 083, Loss: 0.0158\n",
      "Epoch: 084, Loss: 0.0263\n",
      "Epoch: 085, Loss: 0.0141\n",
      "Epoch: 086, Loss: 0.0426\n",
      "Epoch: 087, Loss: 0.0130\n",
      "Epoch: 088, Loss: 0.0294\n",
      "Epoch: 089, Loss: 0.0322\n",
      "Epoch: 090, Loss: 0.0256\n",
      "Epoch: 091, Loss: 0.0386\n",
      "Epoch: 092, Loss: 0.0176\n",
      "Epoch: 093, Loss: 0.0136\n",
      "Epoch: 094, Loss: 0.0167\n",
      "Epoch: 095, Loss: 0.0205\n",
      "Epoch: 096, Loss: 0.0384\n",
      "Epoch: 097, Loss: 0.0223\n",
      "Epoch: 098, Loss: 0.0152\n",
      "Epoch: 099, Loss: 0.0167\n",
      "Epoch: 100, Loss: 0.0303\n",
      "Epoch: 101, Loss: 0.0277\n",
      "Epoch: 102, Loss: 0.0338\n",
      "Epoch: 103, Loss: 0.0221\n",
      "Epoch: 104, Loss: 0.0173\n",
      "Epoch: 105, Loss: 0.0169\n",
      "Epoch: 106, Loss: 0.0187\n",
      "Epoch: 107, Loss: 0.0166\n",
      "Epoch: 108, Loss: 0.0241\n",
      "Epoch: 109, Loss: 0.0139\n",
      "Epoch: 110, Loss: 0.0172\n",
      "Epoch: 111, Loss: 0.0232\n",
      "Epoch: 112, Loss: 0.0144\n",
      "Epoch: 113, Loss: 0.0195\n",
      "Epoch: 114, Loss: 0.0135\n",
      "Epoch: 115, Loss: 0.0165\n",
      "Epoch: 116, Loss: 0.0123\n",
      "Epoch: 117, Loss: 0.0157\n",
      "Epoch: 118, Loss: 0.0187\n",
      "Epoch: 119, Loss: 0.0273\n",
      "Epoch: 120, Loss: 0.0293\n",
      "Epoch: 121, Loss: 0.0158\n",
      "Epoch: 122, Loss: 0.0126\n",
      "Epoch: 123, Loss: 0.0130\n",
      "Epoch: 124, Loss: 0.0076\n",
      "Epoch: 125, Loss: 0.0156\n",
      "Epoch: 126, Loss: 0.0157\n",
      "Epoch: 127, Loss: 0.0208\n",
      "Epoch: 128, Loss: 0.0167\n",
      "Epoch: 129, Loss: 0.0140\n",
      "Epoch: 130, Loss: 0.0285\n",
      "Epoch: 131, Loss: 0.0113\n",
      "Epoch: 132, Loss: 0.0183\n",
      "Epoch: 133, Loss: 0.0184\n",
      "Epoch: 134, Loss: 0.0228\n",
      "Epoch: 135, Loss: 0.0094\n",
      "Epoch: 136, Loss: 0.0169\n",
      "Epoch: 137, Loss: 0.0162\n",
      "Epoch: 138, Loss: 0.0123\n",
      "Epoch: 139, Loss: 0.0235\n",
      "Epoch: 140, Loss: 0.0169\n",
      "Epoch: 141, Loss: 0.0184\n",
      "Epoch: 142, Loss: 0.0085\n",
      "Epoch: 143, Loss: 0.0199\n",
      "Epoch: 144, Loss: 0.0435\n",
      "Epoch: 145, Loss: 0.0195\n",
      "Epoch: 146, Loss: 0.0305\n",
      "Epoch: 147, Loss: 0.0129\n",
      "Epoch: 148, Loss: 0.0115\n",
      "Epoch: 149, Loss: 0.0146\n",
      "Epoch: 150, Loss: 0.0198\n",
      "Epoch: 151, Loss: 0.0185\n",
      "Epoch: 152, Loss: 0.0147\n",
      "Epoch: 153, Loss: 0.0162\n",
      "Epoch: 154, Loss: 0.0164\n",
      "Epoch: 155, Loss: 0.0258\n",
      "Epoch: 156, Loss: 0.0201\n",
      "Epoch: 157, Loss: 0.0209\n",
      "Epoch: 158, Loss: 0.0161\n",
      "Epoch: 159, Loss: 0.0116\n",
      "Epoch: 160, Loss: 0.0213\n",
      "Epoch: 161, Loss: 0.0147\n",
      "Epoch: 162, Loss: 0.0161\n",
      "Epoch: 163, Loss: 0.0168\n",
      "Epoch: 164, Loss: 0.0090\n",
      "Epoch: 165, Loss: 0.0282\n",
      "Epoch: 166, Loss: 0.0169\n",
      "Epoch: 167, Loss: 0.0142\n",
      "Epoch: 168, Loss: 0.0141\n",
      "Epoch: 169, Loss: 0.0282\n",
      "Epoch: 170, Loss: 0.0275\n",
      "Epoch: 171, Loss: 0.0186\n",
      "Epoch: 172, Loss: 0.0253\n",
      "Epoch: 173, Loss: 0.0291\n",
      "Epoch: 174, Loss: 0.0152\n",
      "Epoch: 175, Loss: 0.0284\n",
      "Epoch: 176, Loss: 0.0187\n",
      "Epoch: 177, Loss: 0.0125\n",
      "Epoch: 178, Loss: 0.0165\n",
      "Epoch: 179, Loss: 0.0179\n",
      "Epoch: 180, Loss: 0.0169\n",
      "Epoch: 181, Loss: 0.0149\n",
      "Epoch: 182, Loss: 0.0128\n",
      "Epoch: 183, Loss: 0.0227\n",
      "Epoch: 184, Loss: 0.0174\n",
      "Epoch: 185, Loss: 0.0080\n",
      "Epoch: 186, Loss: 0.0104\n",
      "Epoch: 187, Loss: 0.0152\n",
      "Epoch: 188, Loss: 0.0106\n",
      "Epoch: 189, Loss: 0.0143\n",
      "Epoch: 190, Loss: 0.0382\n",
      "Epoch: 191, Loss: 0.0172\n",
      "Epoch: 192, Loss: 0.0129\n",
      "Epoch: 193, Loss: 0.0157\n",
      "Epoch: 194, Loss: 0.0141\n",
      "Epoch: 195, Loss: 0.0220\n",
      "Epoch: 196, Loss: 0.0183\n",
      "Epoch: 197, Loss: 0.0172\n",
      "Epoch: 198, Loss: 0.0188\n",
      "Epoch: 199, Loss: 0.0215\n",
      "Epoch: 200, Loss: 0.0166\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "data = dataset[0]\n",
    "\n",
    "def train_model():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(output[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(200):\n",
    "    loss_value = train_model()\n",
    "    print(f'Epoch: {epoch+1:03d}, Loss: {loss_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is:0.7560\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "def eval():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(data.x, data.edge_index).argmax(dim=1)\n",
    "        all_correct = (output[data.test_mask]== data.y[data.test_mask]).sum()\n",
    "    return (all_correct/(len(data.y[data.test_mask]))).item()\n",
    "\n",
    "print(f\"Test accuracy is:{eval():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
